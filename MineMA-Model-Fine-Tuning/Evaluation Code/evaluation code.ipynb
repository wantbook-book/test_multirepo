{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67b8d4a9-c371-415b-86fa-10a447a0e9b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\" \n",
    "import pandas as pd\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import torch\n",
    "import warnings\n",
    "from tqdm import tqdm\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "model_id = \"\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    device_map=\"auto\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8db03d8a-1ecf-451e-8245-8e4d006455dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "csv_file = \"\"\n",
    "df = pd.read_csv(csv_file)\n",
    "questions = df['Q'].tolist()\n",
    "answers = df['A'].tolist()\n",
    "\n",
    "sys_mes = \"You are a Large Language Model, and your task is to answer questions posed by users about Minecraft. Utilize your knowledge and understanding of the game to provide detailed, accurate, and helpful responses. Use your capabilities to assist users in solving problems, understanding game mechanics, and enhancing their Minecraft experience.\"\n",
    "correct_count = 0\n",
    "results = []\n",
    "\n",
    "def get_first_letter(answer):\n",
    "    return answer.strip()[0].upper()\n",
    "\n",
    "def contains_unique_option(model_output):\n",
    "    options = ['A', 'B', 'C', 'D']\n",
    "    extended_options = ['A.', 'B.', 'C.', 'D.']\n",
    "    found_options = [opt for opt in options if opt in model_output]\n",
    "    found_extended_options = [opt for opt in extended_options if opt in model_output]\n",
    "    \n",
    "    if len(found_options) == 1:\n",
    "        return True, found_options[0]\n",
    "    elif len(found_extended_options) == 1:\n",
    "        return True, found_extended_options[0][0]\n",
    "    else:\n",
    "        return False, None\n",
    "\n",
    "total_accuracy = 0\n",
    "\n",
    "for run in range(1, 6):\n",
    "    correct_count = 0\n",
    "    results = []\n",
    "\n",
    "    for question, correct_answer in tqdm(zip(questions, answers), total=len(questions), desc=f\"Processing questions - Run {run}\"):\n",
    "        user_mes = f\"\"\"\n",
    "        Based on your knowledge of Minecraft, please answer the following multiple-choice questions with only the option letter.\n",
    "        {question}\n",
    "        \"\"\"\n",
    "\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": sys_mes},\n",
    "            {\"role\": \"user\", \"content\": user_mes},\n",
    "        ]\n",
    "\n",
    "        input_ids = tokenizer.apply_chat_template(\n",
    "            messages,\n",
    "            add_generation_prompt=True,\n",
    "            return_tensors=\"pt\"\n",
    "        ).to(model.device)\n",
    "\n",
    "        terminators = [\n",
    "            tokenizer.eos_token_id,\n",
    "            tokenizer.convert_tokens_to_ids(\"<|eot_id|>\")  #if using LLama-2, then use 'tokenizer.convert_tokens_to_ids(\"</s>\")' \n",
    "        ]\n",
    "\n",
    "        outputs = model.generate(\n",
    "            input_ids,\n",
    "            max_new_tokens=256,\n",
    "            eos_token_id=terminators,\n",
    "            do_sample=True,\n",
    "            temperature=0.6,\n",
    "            top_p=0.9,\n",
    "        )\n",
    "        \n",
    "        response = outputs[0][input_ids.shape[-1]:]\n",
    "        model_output = tokenizer.decode(response, skip_special_tokens=True).strip()\n",
    "        model_answer_first_letter = get_first_letter(model_output)\n",
    "        correct_answer_first_letter = get_first_letter(correct_answer)\n",
    "\n",
    "        is_correct = False\n",
    "        contains_unique, unique_option = contains_unique_option(model_output)\n",
    "        if model_answer_first_letter == correct_answer_first_letter:\n",
    "            is_correct = True\n",
    "        elif contains_unique and unique_option == correct_answer_first_letter:\n",
    "            is_correct = True\n",
    "\n",
    "        if is_correct:\n",
    "            correct_count += 1\n",
    "\n",
    "        results.append({\n",
    "            \"Question\": question,\n",
    "            \"Model Answer\": model_output,\n",
    "            \"Correct Answer\": correct_answer,\n",
    "            \"Is Correct\": is_correct\n",
    "        })\n",
    "\n",
    "    accuracy = correct_count / len(questions)\n",
    "    total_accuracy += accuracy\n",
    "\n",
    "    results_df = pd.DataFrame(results)\n",
    "    results_df.to_csv(f\"{run}.csv\", index=False)\n",
    "\n",
    "    print(f\"Run {run} accuracy: {accuracy * 100:.2f}%\")\n",
    "\n",
    "    with open(\"\", \"a\") as f:\n",
    "        f.write(f\"Run {run} accuracy: {accuracy * 100:.2f}%\\n\")\n",
    "\n",
    "average_accuracy = total_accuracy / 5\n",
    "with open(\"\", \"a\") as f:\n",
    "    f.write(f\"Average accuracy: {average_accuracy * 100:.2f}%\\n\")\n",
    "\n",
    "print(f\"Average accuracy: {average_accuracy * 100:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
